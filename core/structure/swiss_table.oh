# low level data structure that is useful as a foundation for insertion-ordered
# containers that are indexed by an `at`, e.g., insertion-ordered hash maps.
# at a low level, it interleaves a doubly-linked list and a swiss table.
linked_swiss_table_
[    # key for the hash map
     at_
     # what's stored in a element at `at` in the table.
     # can be null if we're a `set_`.
     of_
     slots_per_bucket: count_ = 16
     # type used for counting elements in this table.
     count_: select_count_ = arch_ count_
     count_managed_: managed_
     # if you really want to optimize the size of this struct, we can use
     # some indirection to put `count` in an allocated spot if `on_heap`.
     # usage: `linked_swiss_table_[count_managed_ locally, ...]` or `[count_managed: _ locally, ...]`
     count_managed: _ locally
     # these also optimize the size of the struct (if `on_heap`).
     start_managed_: managed_
     start_managed: _ locally
     end_managed_: managed_
     end_managed: _ on_heap
     first_free_managed_: managed_
     first_free_managed: _ on_heap
]:
[    @private m:
     [    elements; size_optimized_allocation_[element_, header_: element_header_]
          # data for the doubly-linked list.  we don't use a normal DLL because
          # we don't grow this like a stack, we index into it via hash truncation.
          # INVARIANT: each `link_bucket metadata` is always initialized.
          link_buckets; size_optimized_allocation_[link_bucket_, header_: links_header_]
          # for optimal packing, we put all counts here at the end.
          count[require: count_managed == _ locally];
          start[require: start_managed == _ locally]; offset_
          end[require: end_managed == _ locally]; offset_
          first_free[require: first_free_managed == _ locally]; offset_
     ]
]
{    ::count_(): count_
          @if count_managed == _ locally
               m count
          @else
               # TODO: this might be cleaner:
               # `m elements header_() count ?? 0`
               # but we'd have to do something like `vector3?;`, `vector3 x` being nullish,
               # and the corresponding stuff for `hm_` as well.
               m elements header_() map_({$ok count}, {$_er, 0})

     ;;remaining_capacity_(): count_
          m link_buckets capacity_() * slots_per_bucket - m count_()

     # returns an error if there's already an element inside the table
     # with the given `at`.  can also return an error if we are out of memory.
     # see also `replace_`.
     ;;append_(at., of[require: of_ is not_[null_]].): hm_[null_]

     # returns the element `of` that was at `at`, or an error if there wasn't
     # already an element inside the table with the given `at`.
     # see also `append_` and `remove_`.
     ;;replace_[require: of_ is not_[null_]](at:, of.): hm_[of_]
          what m locate_(at)
               _ no_room, _link_offset.
                    er_ no_such_element
               element_offset.
                    of <-> m elements_[element_offset] of

     # returns an error if there's not already an element inside the table
     # with the given `at`, otherwise the element's `of`.
     ;;remove_(at:): hm_[of_]

     # returns the number of elements deleted, should be 0 or 1.
     ;;delete_(at:): count_

     # deletes any elements which match the given `all`.
     # returns the number of elements deleted.
     ;;delete_[require: of_ is not_[null_]](all: of_): count_

     # returns the number of elements deleted, should be 0 or 1.
     ;;delete_[require: of_ is not_[null_]](first: of_): count_

     # returns the number of elements deleted, should be 0 or 1.
     ;;delete_[require: of_ is not_[null_]](last: of_): count_

     # if readonly, returns an error if there's not already an element inside
     # the table with the given `at`.  if writable, returns an error if `at` is
     # not in the table and either we ran out of memory or `of_` is not defaultable.
     ;:at_[require: of_ is not_[null_]](at.): hm_[(of;:)]

     # NOTE TO SELF: we can't do `;;at_(...): (of?;)` because we'll potentially
     # swallow errors (e.g., `map at_(3) = null` should be fine from a memory standpoint,
     # but `map at_(3) = 7` may throw due to running out of memory.
     ::at_[require: of_ is not_[null_]](at.): hm_[(of?:)]

     @private
     ::locate_(at:): one_of_[element_offset: offset_, link_offset: offset_, no_room:]
          full_hash: fast_hash_(at)
          [metadatum:, remaining_hash:] = metadatum_ extract_(full_hash)
          partial_hash: remaining_hash truncate_()

          bucket_count: m link_buckets capacity_()
          slot_count: slots_per_bucket * bucket_count
          offset; full_hash % slot_count
          best_tombstoned_offset?; offset_
          slot_count each _unused_bounds_check:
               offset_metadatum: m metadatum_(offset)
               # TODO: this part can be sped up with SIMD, if available.
               if offset_metadatum cleared_()
                    return [link_offset: best_tombstoned_offset ?? offset]
               elif offset_metadatum filled_()
                    if offset_metadatum == metadatum
                         # there's a good chance we're already a hit.
                         dll_element: m dll_element_(offset)
                         if dll_element partial_hash == partial_hash
                              # there's a very good chance we're already a hit.
                              element_offset: dll_element offset
                              if m elements[element_offset] at == at
                                   return [element_offset]
               else
                    debug assert_(offset_metadatum tombstoned_())
                    if best_tombstoned_offset == null
                         best_tombstoned_offset = offset
               ++offset
          _ no_room

     # shuffles the iteration order of this table
     ;;shuffle_(): null_

     # optimizes this table so that all elements are laid out in order
     # and the linked list goes from left to right contiguously.
     # this is not really necessary to do unless elements have been deleted,
     # or the table has been shuffled/sorted.
     # TODO: should this perform a rehash?  probably?
     ;;defrag_(): null_

     capacity_: count_
     offset_: count_ offset_

     @private
     ;:start_(): (offset_;:) where !!m
          @if start_managed == _ locally
               m start
          @else
               m link_buckets header_(m link_buckets capacity_()) start

     @private
     ;:end_(): (offset_;:) where !!m
          @if end_managed == _ locally
               m end
          @else
               m link_buckets header_(m link_buckets capacity_()) end

     @private
     ;:first_free_(): (offset_;:) where !!m
          @if first_free_managed == _ locally
               m first_free
          @else
               m link_buckets header_(m link_buckets capacity_()) first_free

     @private
     element_header_:
     [    count[require: count_managed == _ on_heap];
     ]

     @private
     link_buckets_header_:
     [    start[require: start_managed == _ on_heap]; offset_
          end[require: end_managed == _ on_heap]; offset_
          # index into `dll` that is the first free in the list.
          # essentially will be a SLL of the tombstoned elements.
          first_free[require: first_free_managed == _ on_heap]; offset_
     ]

     @private
     link_bucket_:
     [    metadata; vector_[slots_per_bucket, metadatum_]
          # the `dll_element`s can have links to other buckets.
          dll; buffer_[slots_per_bucket, dll_element_]
     ]

     @private element_: [at:, of[require: of_ is not_[null_]];]

     @private
     dll_element_:
     [    partial_hash;
          # offsets are not based on buckets; to get the bucket index
          # you use `offset // slots_per_bucket`, and the index within
          # the bucket via `offset %% slots_per_bucket`.
          # similarly for `next` and `previous`.
          offset; offset_
          next; offset_
          previous; offset_
     ]
     @private
     partial_hash_: count_ unsigned_

     @private
     size_optimized_allocation_[of_, header_]: allocation_
     [    of_
          count_
          capacity_managed_ on_heap
          header_
     ]
}

@private
metadatum_: u8_
{    ;;renew_(): null_
          m u8 = 0

     extract_(full_hash. u64_): [metadatum:, remaining_hash:]
          m;
          remaining_hash: m fill_(full_hash)
          [m, remaining_hash]

     ::cleared_(): bool_
          m u8 == 0
     ::filled_(): bool_
          m u8 & present
     ::tombstoned_(): bool_
          m u8 == tombstone

     ;;clear_(): null_
          m u8 = 0
     ;;fill_(full_hash. u64_): [remaining_hash: u64_]
          m u8 = present | (full_hash & 127)
          remaining_hash: full_hash >> 7
     ;;tombstone_(): null_
          m u8 = tombstone

     present: u8_ = 128
     tombstone: u8_ = 127
}
